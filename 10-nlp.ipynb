{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "simple-reception",
   "metadata": {},
   "source": [
    "# Text Analysis (NLP)\n",
    "\n",
    "Taken from [http://openonlinecourses.com/causalanalysis/TextAnalysis.asp](http://openonlinecourses.com/causalanalysis/TextAnalysis.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-custody",
   "metadata": {},
   "source": [
    "## Crawl the directory of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "logical-performer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:16.303537Z",
     "iopub.status.busy": "2022-04-19T03:20:16.303405Z",
     "iopub.status.idle": "2022-04-19T03:20:16.310183Z",
     "shell.execute_reply": "2022-04-19T03:20:16.309720Z",
     "shell.execute_reply.started": "2022-04-19T03:20:16.303503Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "csv_files = list(pathlib.Path('./CSV.Sentiment').glob('*.csv'))\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-joseph",
   "metadata": {},
   "source": [
    "## Build maps\n",
    "\n",
    "These maps will help us map back and forth between the files and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "perceived-weather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:16.311121Z",
     "iopub.status.busy": "2022-04-19T03:20:16.310950Z",
     "iopub.status.idle": "2022-04-19T03:20:16.824158Z",
     "shell.execute_reply": "2022-04-19T03:20:16.823725Z",
     "shell.execute_reply.started": "2022-04-19T03:20:16.311106Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_file_name(file_path):\n",
    "    stem = file_path.stem\n",
    "    stem = stem.replace('+', ' ')\n",
    "    stem = stem.replace('_', '')\n",
    "    stem = stem.replace('.', '')\n",
    "    stem = stem.lower()\n",
    "    stem = stem.strip()\n",
    "    return stem\n",
    "\n",
    "# file-to-id\n",
    "f2i = {str(p): i for i, p in enumerate(csv_files)}\n",
    "\n",
    "# id-to-file\n",
    "i2f = {v: k for k, v in f2i.items()}\n",
    "\n",
    "# file-to-sentence\n",
    "f2s = {f2i[str(p)]: clean_file_name(p) for p in csv_files}\n",
    "\n",
    "# file-to-data\n",
    "f2d = {f2i[str(p)]: pd.read_csv(p)[['comment', 'classification']].assign(comment=lambda d: d['comment'].str.lower()) \n",
    "       for p in csv_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-license",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Let's create vector space models `VSMs` for each one of these corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-effectiveness",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:16.824956Z",
     "iopub.status.busy": "2022-04-19T03:20:16.824849Z",
     "iopub.status.idle": "2022-04-19T03:20:25.520020Z",
     "shell.execute_reply": "2022-04-19T03:20:25.519611Z",
     "shell.execute_reply.started": "2022-04-19T03:20:16.824942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def get_vsm(df, vectorizer_type='count'):\n",
    "    text = df['comment']\n",
    "    \n",
    "    if 'count' == vectorizer_type:\n",
    "        vectorizer = CountVectorizer(max_features=100)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(max_features=100)\n",
    "    \n",
    "    vectorizer.fit(text)\n",
    "    X = vectorizer.transform(text).todense()\n",
    "\n",
    "    count_df = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "    count_df['__y'] = df['classification']\n",
    "    \n",
    "    return {'data': count_df, 'vectorizer': vectorizer}\n",
    "\n",
    "count_vsm = {k: get_vsm(df, vectorizer_type='count') for k, df in f2d.items()}\n",
    "tfidf_vsm = {k: get_vsm(df, vectorizer_type='tfidf') for k, df in f2d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-sender",
   "metadata": {},
   "source": [
    "## Learn models\n",
    "\n",
    "Let's learn a classification model (e.g. Logistic Regression) for each of the VSMs types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "absent-blank",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:25.520654Z",
     "iopub.status.busy": "2022-04-19T03:20:25.520539Z",
     "iopub.status.idle": "2022-04-19T03:20:39.598806Z",
     "shell.execute_reply": "2022-04-19T03:20:39.598448Z",
     "shell.execute_reply.started": "2022-04-19T03:20:25.520640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_model(df):\n",
    "    X = df[[c for c in df.columns if c != '__y']]\n",
    "    y = np.ravel(df['__y'])\n",
    "    \n",
    "    model = LogisticRegression(random_state=37, n_jobs=-1, solver='saga', max_iter=5_000)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "count_models = {k: get_model(v['data']) for k, v in count_vsm.items()}\n",
    "tfidf_models = {k: get_model(v['data']) for k, v in tfidf_vsm.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-shepherd",
   "metadata": {},
   "source": [
    "## Do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relative-convert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:39.599455Z",
     "iopub.status.busy": "2022-04-19T03:20:39.599346Z",
     "iopub.status.idle": "2022-04-19T03:20:39.623962Z",
     "shell.execute_reply": "2022-04-19T03:20:39.623601Z",
     "shell.execute_reply.started": "2022-04-19T03:20:39.599441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_predict(fid):\n",
    "    s = f2s[fid]\n",
    "    f = i2f[fid]\n",
    "    \n",
    "    count_v = count_vsm[fid]['vectorizer']\n",
    "    tfidf_v = tfidf_vsm[fid]['vectorizer']\n",
    "    \n",
    "    count_s = count_v.transform([s]).todense()\n",
    "    tfidf_s = tfidf_v.transform([s]).todense()\n",
    "    \n",
    "    count_m = count_models[fid]\n",
    "    tfidf_m = tfidf_models[fid]\n",
    "    \n",
    "    count_c = count_vsm[fid]['data'].columns\n",
    "    tfidf_c = tfidf_vsm[fid]['data'].columns\n",
    "    \n",
    "    count_p = count_m.predict_proba(count_s)[0,1]\n",
    "    tfidf_p = tfidf_m.predict_proba(tfidf_s)[0,1]\n",
    "    \n",
    "    return {\n",
    "        'file': f,\n",
    "        'sentence': s,\n",
    "        'count_p': count_p,\n",
    "        'tfidf_p': tfidf_p\n",
    "    }\n",
    "    \n",
    "result_df = pd.DataFrame([do_predict(i) for i in range(len(count_models))])\n",
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "robust-platform",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T03:20:39.624612Z",
     "iopub.status.busy": "2022-04-19T03:20:39.624486Z",
     "iopub.status.idle": "2022-04-19T03:20:39.644085Z",
     "shell.execute_reply": "2022-04-19T03:20:39.643711Z",
     "shell.execute_reply.started": "2022-04-19T03:20:39.624595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>count_p</th>\n",
       "      <th>tfidf_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSV.Sentiment/Please+go+find+anyone+else+but+D...</td>\n",
       "      <td>please go find anyone else but dr haque and hi...</td>\n",
       "      <td>0.137457</td>\n",
       "      <td>0.238707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSV.Sentiment/__and+then+never+looked+me+in+th...</td>\n",
       "      <td>and then never looked me in the eye again, pre...</td>\n",
       "      <td>0.561817</td>\n",
       "      <td>0.396794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSV.Sentiment/The+medicine+did+not+taste+terri...</td>\n",
       "      <td>the medicine did not taste terrible</td>\n",
       "      <td>0.614340</td>\n",
       "      <td>0.729197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSV.Sentiment/Go+elsewhere+for+treatment!!__.csv</td>\n",
       "      <td>go elsewhere for treatment!!</td>\n",
       "      <td>0.547714</td>\n",
       "      <td>0.638849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSV.Sentiment/Unprofessional,+Rude,+and+a+sham...</td>\n",
       "      <td>unprofessional, rude, and a shame to the medic...</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.998494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CSV.Sentiment/Granted,+I+am+not+very+far+into+...</td>\n",
       "      <td>granted, i am not very far into healing so thi...</td>\n",
       "      <td>0.072228</td>\n",
       "      <td>0.109858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSV.Sentiment/The+follow-up+care+of+Dr.+Wages+...</td>\n",
       "      <td>the follow-up care of dr wages and his staff a...</td>\n",
       "      <td>0.127893</td>\n",
       "      <td>0.177071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CSV.Sentiment/His+office+nurse+Arri+is+so+unpr...</td>\n",
       "      <td>his office nurse arri is so unprofessional and...</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.045120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CSV.Sentiment/Great+experience-+very+friendly+...</td>\n",
       "      <td>great experience- very friendly and prompt plu...</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.004252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CSV.Sentiment/I+wish+I+could+select+a+lot+more...</td>\n",
       "      <td>i wish i could select a lot more than five stars</td>\n",
       "      <td>0.288483</td>\n",
       "      <td>0.300915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CSV.Sentiment/His+consultation+and+the+follow+...</td>\n",
       "      <td>his consultation and the follow up with him an...</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.020423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CSV.Sentiment/A+very+uneventful+experience+whe...</td>\n",
       "      <td>a very uneventful experience when it came down...</td>\n",
       "      <td>0.153085</td>\n",
       "      <td>0.345291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CSV.Sentiment/We+should+have+known+better+than...</td>\n",
       "      <td>we should have known better than to trust dr h...</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>0.092493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CSV.Sentiment/__Everything+seems+to+be+on+sche...</td>\n",
       "      <td>everything seems to be on schedule</td>\n",
       "      <td>0.037970</td>\n",
       "      <td>0.088021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CSV.Sentiment/I+never+imagined+I+would+look+th...</td>\n",
       "      <td>i never imagined i would look this good!</td>\n",
       "      <td>0.244954</td>\n",
       "      <td>0.270404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CSV.Sentiment/And+I+feel+immense+gratitude+for...</td>\n",
       "      <td>and i feel immense gratitude for dr schwartz's...</td>\n",
       "      <td>0.137810</td>\n",
       "      <td>0.171935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CSV.Sentiment/DO+NOT+GO+TO+THIS+DENTIST.csv</td>\n",
       "      <td>do not go to this dentist</td>\n",
       "      <td>0.453572</td>\n",
       "      <td>0.448374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CSV.Sentiment/but+I+sometimes+felt+that+I+had+...</td>\n",
       "      <td>but i sometimes felt that i had to ask a lot o...</td>\n",
       "      <td>0.401821</td>\n",
       "      <td>0.468207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CSV.Sentiment/but+not+like+the+modeled+image+I...</td>\n",
       "      <td>but not like the modeled image i was shown</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>0.617548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CSV.Sentiment/I+highly+recommend+seeing+Ashley...</td>\n",
       "      <td>i highly recommend seeing ashley if you're not...</td>\n",
       "      <td>0.131895</td>\n",
       "      <td>0.184679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CSV.Sentiment/The+folks+are+very+personable+an...</td>\n",
       "      <td>the folks are very personable and helpful</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.007035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CSV.Sentiment/But+afterwards,+I+felt+that+the+...</td>\n",
       "      <td>but afterwards, i felt that the details disapp...</td>\n",
       "      <td>0.375071</td>\n",
       "      <td>0.343731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CSV.Sentiment/Thanks+for+the+supplements,+I+wi...</td>\n",
       "      <td>thanks for the supplements, i will give them a...</td>\n",
       "      <td>0.257987</td>\n",
       "      <td>0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CSV.Sentiment/__I+did+my+research+and+I+decide...</td>\n",
       "      <td>i did my research and i decided not to go with...</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>0.394091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CSV.Sentiment/I+have+never+gone+in+and+waited+...</td>\n",
       "      <td>i have never gone in and waited less than 30 m...</td>\n",
       "      <td>0.428213</td>\n",
       "      <td>0.402648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "0   CSV.Sentiment/Please+go+find+anyone+else+but+D...   \n",
       "1   CSV.Sentiment/__and+then+never+looked+me+in+th...   \n",
       "2   CSV.Sentiment/The+medicine+did+not+taste+terri...   \n",
       "3    CSV.Sentiment/Go+elsewhere+for+treatment!!__.csv   \n",
       "4   CSV.Sentiment/Unprofessional,+Rude,+and+a+sham...   \n",
       "5   CSV.Sentiment/Granted,+I+am+not+very+far+into+...   \n",
       "6   CSV.Sentiment/The+follow-up+care+of+Dr.+Wages+...   \n",
       "7   CSV.Sentiment/His+office+nurse+Arri+is+so+unpr...   \n",
       "8   CSV.Sentiment/Great+experience-+very+friendly+...   \n",
       "9   CSV.Sentiment/I+wish+I+could+select+a+lot+more...   \n",
       "10  CSV.Sentiment/His+consultation+and+the+follow+...   \n",
       "11  CSV.Sentiment/A+very+uneventful+experience+whe...   \n",
       "12  CSV.Sentiment/We+should+have+known+better+than...   \n",
       "13  CSV.Sentiment/__Everything+seems+to+be+on+sche...   \n",
       "14  CSV.Sentiment/I+never+imagined+I+would+look+th...   \n",
       "15  CSV.Sentiment/And+I+feel+immense+gratitude+for...   \n",
       "16        CSV.Sentiment/DO+NOT+GO+TO+THIS+DENTIST.csv   \n",
       "17  CSV.Sentiment/but+I+sometimes+felt+that+I+had+...   \n",
       "18  CSV.Sentiment/but+not+like+the+modeled+image+I...   \n",
       "19  CSV.Sentiment/I+highly+recommend+seeing+Ashley...   \n",
       "20  CSV.Sentiment/The+folks+are+very+personable+an...   \n",
       "21  CSV.Sentiment/But+afterwards,+I+felt+that+the+...   \n",
       "22  CSV.Sentiment/Thanks+for+the+supplements,+I+wi...   \n",
       "23  CSV.Sentiment/__I+did+my+research+and+I+decide...   \n",
       "24  CSV.Sentiment/I+have+never+gone+in+and+waited+...   \n",
       "\n",
       "                                             sentence   count_p   tfidf_p  \n",
       "0   please go find anyone else but dr haque and hi...  0.137457  0.238707  \n",
       "1   and then never looked me in the eye again, pre...  0.561817  0.396794  \n",
       "2                 the medicine did not taste terrible  0.614340  0.729197  \n",
       "3                        go elsewhere for treatment!!  0.547714  0.638849  \n",
       "4   unprofessional, rude, and a shame to the medic...  0.999406  0.998494  \n",
       "5   granted, i am not very far into healing so thi...  0.072228  0.109858  \n",
       "6   the follow-up care of dr wages and his staff a...  0.127893  0.177071  \n",
       "7   his office nurse arri is so unprofessional and...  0.025998  0.045120  \n",
       "8   great experience- very friendly and prompt plu...  0.000726  0.004252  \n",
       "9    i wish i could select a lot more than five stars  0.288483  0.300915  \n",
       "10  his consultation and the follow up with him an...  0.001607  0.020423  \n",
       "11  a very uneventful experience when it came down...  0.153085  0.345291  \n",
       "12  we should have known better than to trust dr h...  0.066040  0.092493  \n",
       "13                 everything seems to be on schedule  0.037970  0.088021  \n",
       "14           i never imagined i would look this good!  0.244954  0.270404  \n",
       "15  and i feel immense gratitude for dr schwartz's...  0.137810  0.171935  \n",
       "16                          do not go to this dentist  0.453572  0.448374  \n",
       "17  but i sometimes felt that i had to ask a lot o...  0.401821  0.468207  \n",
       "18         but not like the modeled image i was shown  0.559091  0.617548  \n",
       "19  i highly recommend seeing ashley if you're not...  0.131895  0.184679  \n",
       "20          the folks are very personable and helpful  0.006247  0.007035  \n",
       "21  but afterwards, i felt that the details disapp...  0.375071  0.343731  \n",
       "22  thanks for the supplements, i will give them a...  0.257987  0.220403  \n",
       "23  i did my research and i decided not to go with...  0.411447  0.394091  \n",
       "24  i have never gone in and waited less than 30 m...  0.428213  0.402648  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
